<html>
	<head>
		<style type="text/css">
			body{font-family: sans-serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 18px;padding: 1%;}
			.section{position: relative;width: 90%;margin: auto;padding: 2%;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 14px;font-weight: bold;}
			.text{width: 95%;font-size: 12px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 12px;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<font face="Verdana" >
		<div class="container">
			<div class="title" style="color:DodgerBlue;">ACTIVITY RECOGNITION USING  CELL-PHONE ACCCELEROMETER</div>

			<div class="authors">

				<!-- Start edit here  -->
				<p>E PONGBA KONYAK, Roll No.: 150102018, Branch: ECE</p>; &nbsp; &nbsp;
				<p>GIRIJA SHANKAR KUANR, Roll No.: 150102020, Branch: ECE</p>; &nbsp; &nbsp;
				<!-- Stop edit here -->

			</div>


			<div class="section">
				<div class="heading"><font size="3" color="red">ABSTRACT</font></div>
				<div class="text">

					<!-- Start edit here  -->
					Mobile devices are becoming increasingly sophisticated and they have many sensors like GPS sensors, vison sensors(i.e.,camera), audio sensors(i.e.,microphones),light sensors,temperature sensors,direction sensors and acceleration sensors(i.e.,accelerometers).In this project we describe and evaluate a system that uses phone based accelerometers to perform activity recognition, a task which involves identifying the physical activity a user is performing.To implement our system we collected labeled accelerometer data from 10 users as they performed daily activities such as walking ,jogging,climbing stairs,sitting and standing,and then aggrgated this time series data into examples that suumerise the user activity over 10 second intervals. We then used the reslting training data to induce a predictive model for activity recognition.Our work has a wide range of application including automatic customization of the model of the mobile device's behaviour based upon a user's activity(e.g.,sending calls directly to voicemail if a user is jogging).
					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading"><font size="3" color="blue">1. Introduction</font></div>
				<div class="text">

					<!-- Start edit here  -->
					Mobile devices such as cellular phones and music players have recently begun to incorporate diverse and powerful sensors.
					<!-- Stop edit here -->
					<div class="image">

						<!-- Start edit here  -->
						
						<img src="Pictures/example.jpg
							  
							  
							  " alt="This text displays when the image is umavailable" width="300px" height=""/>
						<!-- Stop edit here -->

					</div>
					The goal of our WISDM(Wireless Data Mining) project is to explore the research issues related to mining sensor data from these powerful mobile devices and to build useful aplications.In this project we explore the use of one of these sensors, the accelerometer,in order to identify the activity that the user is performing.Nowadays many android phones contain tri-axial accelerometers that measure acceleration in all three spatial dimensions.These accelerometers are also capable of detecting the orientation of the device which can provide useful information for activity recognition.For e.g we can automatically moniter a user's activity level and generate daily,weekly and monthly activity reports.The activity information can also be used to automatically customize the behaviour of the mobile phone e.g,music could automatically be selected to match the activity or send calls directly to voice mail when the user is exercising etc.<br>
					
			
			        </div>

				<div class="subsection">
					<div class="heading">1.1 Introduction to Problem</div>
					<div class="text">

				                <!-- Start edit here  -->
						When we watch a person, it is easy for us to tell what activity they are performing even if we have never seen them in the past. This is because our brains are already trained to understand human activities. When viewing the activity, the brain compares it to thousands of activities it has memorized and pops out the one that matches. Similarly, a computer (or phone) can identify the activity we are performing based on activities we have trained it to identify.
						<p>On a computer, a machine learning, Applying a classification algorithm to this task involves two steps: training and detection. The training step builds a model which maps training data to certain categories. The detection step maps new data to a category.g algorithm can be used to “learn” human activities and detect the activity being performed for the new data that is collected. A detection task such as this, which involves categorizing data into separate “classes” is called classification. Another example of a classification task would be assigning a diagnosis to a patient as described by presence of certain symptoms.</p>
						<p>Applying a classification algorithm to this task involves two steps: training and detection. The training step builds a model which maps training data to certain categories. The detection step maps new data to a category.</p>
						<p>In our application, we used the acceleration sensor (accelerometer) in our Android phone to help identify the activity that someone is performing. We chose the K-Nearest Neighbor (KNN) classifier. This is a suitable algorithm for our application because it can detect the activity very quickly and has good accuracy while working with low dimensional data (a small set of features). It detects the category to which a new data point belongs to by taking a majority vote of its closest K neighbors in the training data set.</p>
						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading">1.2 Figure</div>
					<div class="image">
						<img src="Pictures/Screenshot (7).jpeg"/>
						<img src="Pictures/Screenshot (8).jpeg"/>	  

						<!-- Start edit here  -->
						
						
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						<p>Activity recognition has recently gained attention as a research topic because of the increasing availability of accelerometers in consumer products, like cell phones, and because of the many potential applications. Some of the earliest work in accelerometerbased activity recognition focused on the use of multiple accelerometers placed on several parts of the user’s body. In one of the earliest studies of this topic, Bao & Intille [3] used five biaxial accelerometers worn on the user’s right hip, dominant wrist, nondominant upper arm, dominant ankle, and non-dominant thigh in order to collect data from 20 users. Using decision tables, instance-based learning, C4.5 and Naïve Bayes classifiers, they created models to recognize twenty daily activities. Their results indicated that the accelerometer placed on the thigh was most powerful for distinguishing between activities. This finding supports our decision to have our test subjects carry the phone in the most convenient location—their pants pocket.</p>
						<p>Some studies have also focused on combining multiple types of sensors in addition to accelerometers for activity recognition. Maurer et al. used “eWatch” devices placed on the belt, shirt pocket, trouser pocket, backpack, and neck to recognize the same activities that we consider in our study</p>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						<ul>
						  The process of detecting activities was performed in three steps:
1) Data Collection: we collected the 3-dimensional acceleration data from the accelerometer on our Android phone.
2) Feature Extraction: we identified and extracted distinct features in the accelerometer data for each activity that we wanted to detect.
3) Activity Classification: we used the features extracted for the various activities to train the classifier. The classifier was then used on new accelerometer data to identify the activity being performed.
						<ul>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						<ol>
							<li>Title and authors </li>
							<li>Abstract</li>
							<li>Introduction</li>
							<li>Proposed Approach</li>
							<li>Experiment and Results</li>
							<li>Conclusion(summary and future extension)</li>
						</ol>		
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading"><font size="3" color="blue">2. Proposed Approach</font></div>
				<div class="text">

					<!-- Start edit here  -->
					<ul>
					  <li>Firstly, we will place the cell phone(i.e, accelerometer) in the front pocket of the pant.</li>
					  <li>Then informative features based on raw accelerometer readings are generated.</li>
					  <li>Each reading contains X,Y and Z values corresponding to the three axes/dimensions</li>
					  For this purposes,
              			<ol>
						  <li>Z-axis:captures the forward movement of the leg.</li>
						  <li>Y-axis:captures the upward and downward motion.</li>
						  <li>X-axis:captures the horizontal movement of the user's leg.</li>
						  These axes are relative to a user.
						</ol>
						<div class="image">

							<!-- Start edit here  -->
						
							<img src="Pictures/motion.png" alt="This text displays when the image is umavailable" width="300px" height=""/>
							<!-- Stop edit here -->

						</div>
					   <div class="heading">2.1 Data Collection</div>
					          <div class="text"><p>While the detection was performed by a classifier, it needed to be trained by a set of known data points to make it work. MATLAB Mobile, in conjunction with the MATLAB Support Package for Android Sensors, enabled me to gather data from the device’s accelerometer and send the subsequent measurements to the MATLAB session on my computer.</p>
							            <p> One of the group member performed the activities like walking,climbing up stairs,climbing downstairs,standing,running.Then we acquire the three dimensional acceleration data that was recorded by celphone accelerometer.</p>
				           </div>	  
					   <div class="heading">2.2 Feature Extraction</div>
						  <div class="text">There are several different possible features which can be considered for extraction for ex: mean, standard deviation,median etc.But we used the following features that we found most suitable for our project.
							            <ol type="1">
									    <li> The mean of magnitude data</li>
									    <li> The squared sum of magnitude data below 25 percentile</li>
									    <li> The squared sum of magnitude data below 75 percentile</li>
									    <li> Peak frequency in spectrum of y-axis data below 5 Hz</li>
									    <li> Number of peaks in specrum of y-axis</li>
									    <li> Integral of specrum of y-axis data from 0 to 5Hz</li>
								     </ol>
							   After calculating the above 6 features for the different activities
performed as a part of the training procedure, we fed the training algorithm two inputs: the features and the appropriate response (i.e. the activity the feature denotes).
						 </div>
					   <div class="heading">2.3 Activity classification</div>		  
			                          <div class="text">
							In general, a training algorithm requires many training data points to build a reliable model for detection. To this extent, we collected over a thousand training data points of each activity for classifier training.
							To begin with, I grouped the features in an array in the following order – Walking, Running, Idling, Climbing upstairs and Going downstairs.We stored the data in 6 files. featurewalk is a 100x6 array of 6 features the raw accelerometer data collected while one group member was walking. Similarly, featureRun is a 1000×6 array of six features calculated using the raw accelerometer data collected while the member was running, and so on. Once we had the features for all the activities in the data array, we noticed that features corresponding to Run were on a relatively larger scale than features corresponding to either Idle or Walking state. This creates a bias in a feature across different activities and will affect the capability of the algorithm to accurately detect the activity being performed for new data (which might be scaled differently). Therefore, we normalized the values in data to confine the range of values to be between [0, 1].Once I had the features for all the activities in the data array, I noticed that features corresponding to Run were on a relatively larger scale than features corresponding to either Idle or Walking state. This creates a bias in a feature across different activities and will affect the capability of the algorithm to accurately detect the activity being performed for new data (which might be scaled differently). Therefore, we normalized the values in data to confine the range of values to be between [0, 1].
							 nce the data was normalized and ready to be used, I had to define the response that the machine learning algorithm has to output when it receives the data array as an input. The input data and the output response would then be used to teach the machine algorithm how to classify new data. To build the output response vector, I first assigned an integer for each activity: -1, 0, 1, 2, 3 for going downstairs, idling, climbing upstairs, walking and running respectively. Since I need a response for each input feature set, I created a column vector (containing these integers) of the length of training feature data points of each activity as the response vector. To make the detected activity easily human readable, I converted the response vector to a categorical array with values ‘Going Downstairs’, ‘Idling’, ‘Climbing Upstairs’, ‘Walking’, ‘Running’ and ‘Transition.After generating the response array above, I then trained the K-NN algorithm to obtain a model. To do this, I used the FITCKNN function from Statistics Toolbox; For this application, after a few trials, we chose K (‘NumNeighbors’ property) to be 30 as this provided the required performance and accuracy for detection.Having generated a model using the training data, I wanted to use it on new data from my phone to validate the detected activity and thereby validate the model. For this, I used the custom function called extractFeature MATLAB function to calculate the six features of interest. The calculated features (saved to the newFeature variable) are then used along with the model to detect the activity being performed.
							  

					   </div>
					<!-- Stop edit here -->

				</div> 
			</div>

			<div class="section">
				<div class="heading"><font size="3" color="blue">3. Experiments &amp; Results</font></div>
				<div class="subsection">
					<div class="heading">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						Human activity understanding has become one of the most active research topics in computer vision. The type and amount of data that each approach uses depends on the ability of the underlying algorithm to deal with large scale data. The first step in developing a human activity recognition system is to acquire an adequate human activity database. This database is used for training and testing purposes. We use this dataset for feature extraction using various method such as mean of magnitude data,etc .Then we use the various classifier (one of them is k-means) to train as well as to check the result.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading"><font size="3" color="blue">4. Conclusions</font></div>
				<div class="subsection">
					<div class="heading">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						 <ul>
						   <li>Smart phone can be used to perform activity recognition simply by keeping it in once's pocket.</li>
						   <li>We further showed that our recognition can detect activities independent of smart phone's position.</li>
						   <li>We further showed that activity recognition can be highly accurate,with most activities being recognised correctly over 90% of the time.</li>
						   <li>In addition, these activities can be recognised quickly since each example is generated from only 10 second worth of data.</li>
						 </ul>
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						For future work,we plan to extend our activity recognition task in several ways.First,we intend to recognize additional activities,such as bicycling or sleeping.Second we would like to collect data from more users of various ages.Third we plan to extract more features that could better discriminate different activities.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
				</font>
	</body>
</html>
